{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rndsrc/2024_nobel-phys_hs/blob/main/Hopfield.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Exploring the 2024 Nobel Prize in Physics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 0. Setup (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Access the Notebook\n",
    "\n",
    "To start working with this notebook, open it using one of the following methods:\n",
    "\n",
    "- [**GitHub Codespaces**](https://github.com/features/codespaces): If you are using a GitHub repository, you can launch a Codespace, which provides an online VS Code environment with Jupyter support.\n",
    "- [**Google Colab**](https://colab.research.google.com/): If you prefer a cloud-based Python environment, open this notebook in Google Colab.\n",
    "- **Local Jupyter Lab:** If you have Jupyter installed on your machine, run the following command in your terminal:\n",
    "  ```sh\n",
    "  jupyter lab\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Quick Tour of Jupyter Notebook\n",
    "\n",
    "Jupyter Notebook consists of **cells** that can contain either **Markdown** (formatted text) or **Python code**.\n",
    "\n",
    "- **Markdown Cells:** Used for documentation and instructions.\n",
    "  Double-click a cell to edit it, and press `Shift + Enter` to render it.\n",
    "- **Code Cells:** Used to write and execute Python code.\n",
    "  Click inside a cell and press `Shift + Enter` to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Example: Run Your First Python Code\n",
    "\n",
    "Try running the following code cell to check if Python is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a welcome message\n",
    "def greet():\n",
    "    return \"Welcome to the Hopfield Network Notebook!\"\n",
    "\n",
    "print(greet())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Installing Dependencies (if needed)\n",
    "\n",
    "In a Jupyter Notebook, an `!` (exclamation mark) is used to execute shell (command-line) commands directly from a code cell.\n",
    "This allows users to run commands as they would in a terminal, without leaving the notebook.\n",
    "If running this notebook locally, ensure you have the required libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command\n",
    "\n",
    "!pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "This concludes the setup!\n",
    "Now, let's dive into Hopfield networks and their connection to the Ising model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 1. Introduction (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### What is the 2024 Nobel Prize in Physics About?\n",
    "\n",
    "In 2024, the **Nobel Prize in Physics** was awarded to **John J. Hopfield** and **Geoffrey E. Hinton** for their pioneering work on neural networks.\n",
    "Their contributions have played a significant role in the development of modern artificial intelligence and computational models inspired by biological learning mechanisms.\n",
    "\n",
    "- **John J. Hopfield** introduced the Hopfield network, a type of recurrent neural network that models associative memory and collective computation in neural systems.\n",
    "- **Geoffrey E. Hinton** made significant advancements in deep learning, particularly in training deep neural networks through the backpropagation algorithm.\n",
    "\n",
    "Their research has had profound implications in artificial intelligence, neuroscience, and computational physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Why Do Neural Networks Matter?\n",
    "\n",
    "Neural networks are now an essential part of many everyday technologies:\n",
    "\n",
    "- **Facial Recognition:** Used to unlock smartphones and enhance security.\n",
    "- **Chatbots:** Power customer service agents that interact with users.\n",
    "- **Voice Assistants:** Siri, Alexa, and Google Assistant rely on neural networks for speech recognition.\n",
    "- **Self-Driving Cars:** Autonomous vehicles process sensor data using deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Importance of This Discovery\n",
    "\n",
    "Neural networks have revolutionized multiple domains, including:\n",
    "- **Language Translation:** Real-time translation services are powered by deep learning models.\n",
    "- **Medical Diagnosis:** AI-assisted analysis of medical images improves diagnostic accuracy.\n",
    "- **Scientific Research:** AI-driven simulations enhance modeling in physics, chemistry, and biology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 2. The Ising Model (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### What Is the Ising Model?\n",
    "\n",
    "To understand how neural networks operate, we first introduce the **Ising model**.\n",
    "\n",
    "The **Ising model** is a mathematical model in statistical mechanics, introduced by Wilhelm Lenz in 1920 and solved for the one-dimensional case by his student Ernst Ising in 1925.\n",
    "The model was originally used to explain ferromagnetism, where magnetic materials exhibit spontaneous magnetization due to interactions between neighboring atomic spins.\n",
    "\n",
    "- Wilhelm Lenz conceived the model as a simplified representation of magnetic interactions in a lattice, where spins can either point \"up\" (+1) or \"down\" (-1).\n",
    "- Ernst Ising solved the one-dimensional version of the model in his doctoral thesis, showing that it did not exhibit phase transitionsâ€”a result that was surprising at the time.\n",
    "- Lars Onsager solved the two-dimensional version of the model in 1944, demonstrating that it undergoes a phase transition at a critical temperature, where spontaneous magnetization occurs.\n",
    "\n",
    "Since then, the Ising model has become one of the most widely studied models in statistical physics and beyond.\n",
    "Its applications extend not only to physics (such as in magnetism and lattice gases) but also to fields like biology (neural networks), computer science (optimization problems), and even sociology (modeling opinion dynamics).\n",
    "\n",
    "The **Metropolis algorithm** (1953) was developed for Monte Carlo simulations of systems like the Ising model, enabling the study of large, complex systems by simulating their thermal fluctuations and statistical properties.\n",
    "This method revolutionized computational physics and remains a powerful tool in many areas of research today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Basic Idea\n",
    "\n",
    "- Consider a **grid (lattice)** where each point represents a **spin**.\n",
    "- Each spin can take one of two states: **up (+1) or down (-1)**.\n",
    "- Spins interact with their neighbors, aiming to align in a way that minimizes system energy.\n",
    "- The system's **energy parameter** determines the likelihood of spins flipping, making temperature a crucial factor in system behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Interaction and Energy Minimization\n",
    "\n",
    "- The system's total energy is determined by how well-aligned the spins are with their neighbors.\n",
    "- At **high temperatures**, spins flip frequently due to thermal fluctuations, leading to disorder.\n",
    "- At **low temperatures**, spins align into ordered configurations, exhibiting phase transitions similar to those in magnetic materials.\n",
    "- The **Hamiltonian** (energy function) for the Ising model is:\n",
    "  $$\n",
    "  H = - \\sum_{i,j} J_{ij} s_i s_j\n",
    "  $$\n",
    "  where:\n",
    "  - $s_i$ represents the spin at site $i$.\n",
    "  - $J_{ij}$ is the coupling strength between neighboring spins.\n",
    "- The system evolves dynamically to minimize $H$, leading to patterns of stable configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Energy Change Due to Spin Flip\n",
    "\n",
    "When a single spin $s_i$ flips, the change in energy is calculated by comparing the energy before and after the flip.\n",
    "The energy difference $\\Delta E$ due to flipping the spin at site $i$ is:\n",
    "$$\n",
    "\\Delta E = 2 s_i \\sum_{j} J_{ij} s_j,\n",
    "$$\n",
    "where the sum is over the nearest neighbors $j$ of site $i$.\n",
    "The factor of 2 arises because flipping the spin at site $i$ changes its contribution to the energy from $-s_i s_j$ to $+s_i s_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Metropolis Algorithm\n",
    "\n",
    "To simulate the evolution of the system at a given temperature, we use the Metropolis algorithm.\n",
    "This algorithm probabilistically accepts or rejects a spin flip based on the energy change $\\Delta E$ and the temperature $T$.\n",
    "The probability of accepting a spin flip is given by the Boltzmann factor:\n",
    "$$\n",
    "P(\\text{flip}) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } \\Delta E < 0, \\\\\n",
    "\\exp\\left(-\\frac{\\Delta E}{k_B T}\\right) & \\text{if } \\Delta E \\geq 0,\n",
    "\\end{cases}\n",
    "$$\n",
    "where:\n",
    "- $\\Delta E$ is the energy change caused by the flip.\n",
    "- $k_\\mathrm{B}$ is the Boltzmann constant.\n",
    " $T$ is the temperature.\n",
    "\n",
    "This allows the system to \"explore\" higher energy states at higher temperatures (thermal fluctuations), while favoring low-energy configurations as the system cools down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Why It Matters\n",
    "\n",
    "#### Real-World Example: Magnets and Decision-Making\n",
    "- In **magnetism**, atomic spins align to form magnetic domains, illustrating how interactions shape large-scale behavior.\n",
    "- In **social dynamics**, human decision-making can resemble an Ising model, where individuals adjust their opinions based on peer influence.\n",
    "\n",
    "#### Optimization\n",
    "- Many complex optimization problems, including **image recognition and combinatorial search problems**, can be formulated using the Ising model framework.\n",
    "- The process of **energy minimization** in the Ising model is analogous to **error minimization** in machine learning.\n",
    "- Neural networks, particularly **Hopfield networks** that we will present later, use a similar principle to find stable memory states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 3. Hands-On Activity: Simulating a 2D Ising Model (10 min)\n",
    "\n",
    "Here, we provide sample python codes to implement the Ising Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import useful packages `numpy` and `matplotlib`\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image  as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easy comparison of simulation paramaters, we will implement the Ising model as a python class.\n",
    "\n",
    "class IsingModel:\n",
    "    \"\"\"\n",
    "    Ising Model Class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, T, shape=(64,64)):\n",
    "        \"\"\"\n",
    "        Initialize the Ising Model.\n",
    "        \n",
    "        Parameters:\n",
    "          T: Temperature of the system.\n",
    "          shape: The size of the 2D spin lattice.\n",
    "        \"\"\"\n",
    "        self.T     = T      # Temperature\n",
    "        self.shape = shape  # Lattice size\n",
    "        self.state = None   # Initialize the spin state\n",
    "\n",
    "    def random(self, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize the spin lattice randomly with +1 and -1.\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)  # Ensure reproducibility\n",
    "        self.state = np.random.choice([-1,1], size=self.shape)  # Random spins\n",
    "\n",
    "    @staticmethod\n",
    "    def dE(state, i, j):\n",
    "        \"\"\"\n",
    "        Calculate the change in energy when flipping a spin at (i, j).\n",
    "        \"\"\"\n",
    "        I, J = state.shape  # Get lattice dimensions\n",
    "        spin = state[i, j]  # Current spin value\n",
    "        # Neighboring spins (periodic boundary conditions)\n",
    "        neighbors = state[(i+1)%I, j] + state[(i-1)%I, j] + state[i, (j+1)%J] + state[i, (j-1)%J]\n",
    "        return 2 * spin * neighbors  # Energy difference due to spin flip\n",
    "\n",
    "    @staticmethod\n",
    "    def flip(state, i, j, T):\n",
    "        \"\"\"\n",
    "        Decide whether to flip a spin at (i, j) based on the Metropolis algorithm.\n",
    "        \"\"\"\n",
    "        dE = IsingModel.dE(state, i, j)  # Compute energy change\n",
    "        if dE < 0:\n",
    "            return True  # Always accept flip if energy decreases\n",
    "        else:\n",
    "            return np.random.rand() < np.exp(-dE / T)  # Accept flip with Boltzmann probability\n",
    "\n",
    "    @staticmethod\n",
    "    def step(state, i, j, T):\n",
    "        \"\"\"\n",
    "        Perform a single spin flip step if accepted.\n",
    "        \"\"\"\n",
    "        if IsingModel.flip(state, i, j, T):\n",
    "            state[i, j] *= -1  # Flip the spin\n",
    "\n",
    "    def run(self, N):\n",
    "        \"\"\"\n",
    "        Run the Monte Carlo simulation for N steps.\n",
    "        \"\"\"\n",
    "        for n in range(N):\n",
    "            i = np.random.randint(0, self.shape[0])  # Random row index\n",
    "            j = np.random.randint(0, self.shape[1])  # Random column index\n",
    "            self.step(self.state, i, j, self.T)      # Attempt to flip the spin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup an Ising Model\n",
    "I = IsingModel(1)  # Initialize the Ising model at a given temperature\n",
    "I.random()         # Set up a random spin configuration\n",
    "I.run(64*64*100)   # Run the simulation for a certain number of steps\n",
    "\n",
    "# Display the final state of the spin lattice\n",
    "plt.imshow(I.state, cmap='gray')\n",
    "plt.title(\"Final Spin Configuration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDS-ON: instead of just visualizing the final output, implement a loop to create a movie\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDS-ON: plot magnetization, i.e., sum(state) / state.size, as a function of step\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDS-ON: plot magnetization for different temperature\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 4. Hopfield Networks (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Memory Machines\n",
    "\n",
    "The **Hopfield network**, introduced by **John Hopfield in 1982**, is a recurrent neural network that stores and recalls patterns through energy minimization.\n",
    "\n",
    "- **Pattern Storage and Recall:** The network can store multiple patterns as stable configurations.\n",
    "- **Robustness to Noise:** If an input is noisy or incomplete, the network still retrieves the correct stored pattern.\n",
    "- **Content-Addressable Memory:** Unlike conventional memory, which retrieves data using addresses, Hopfield networks retrieve patterns based on similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Energy Landscape\n",
    "\n",
    "The Hopfield network shares deep similarities with the Ising model:\n",
    "- **Neurons replace spins**, taking binary values $+1$ or $-1$.\n",
    "- **Connections between neurons** correspond to interactions between spins.\n",
    "- **The system evolves toward stable, low-energy states**, just like in the Ising model.\n",
    "- **Both exhibit emergent global order** despite being governed by local interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "The energy function of the Hopfield network is given by:\n",
    "$$\n",
    "E = - \\sum_{i,j} W_{ij} \\sigma_i \\sigma_j,\n",
    "$$\n",
    "where $W_{ij}$ represents synaptic weights and $\\sigma_i$ is the neuron state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "When a neuron updates, its **energy change** follows:\n",
    "$$\n",
    "\\Delta E = 2 \\sigma_i \\sum_j W_{ij} \\sigma_j.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Why It Matters\n",
    "\n",
    "The Hopfield network played a **foundational role in artificial intelligence** by introducing energy-based models:\n",
    "- Inspired later developments such as **Boltzmann machines** and **Deep Learning architectures**.\n",
    "- Showed how memory and pattern recognition could emerge from simple neuron interactions.\n",
    "- Provided insights into **biological neural networks**, helping us understand how the brain processes and retrieves information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Hebbian Learning Rule\n",
    "\n",
    "The weights in a Hopfield network are learned using the Hebbian learning rule, which strengthens the connections between neurons that are activated together.\n",
    "It is given by:\n",
    "$$\n",
    "W_{ij} = \\frac{1}{P} \\sum_p \\sigma_i^{(p)} \\sigma_j^{(p)}.\n",
    "$$\n",
    "Where:\n",
    "* $N$ is the number of neurons.\n",
    "* $P$ is the number of patterns.\n",
    "* $\\sigma_i^{(p)}$ is the state of neuron $i$ in a pattern $p$.\n",
    "\n",
    "This makes Hopfield networks **powerful for associative memory**, allowing pattern retrieval even with noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## 5. Hands-On Activity: Building a Hopfield Network (10 min)\n",
    "\n",
    "In this section, we will implement a **Hopfield Network** and train it to recognize patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hopfield Network Class\n",
    "\n",
    "class HopfieldNetwork:\n",
    "    \"\"\"\n",
    "    Hopfield Network Class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, shape=(64, 64)):\n",
    "        \"\"\"\n",
    "        Initialize the Hopfield network.\n",
    "        \n",
    "        Parameters:\n",
    "          shape: The size of the 2D pattern.\n",
    "        \"\"\"\n",
    "        self.shape = shape\n",
    "        self.W     = np.zeros((shape[0] * shape[1], shape[0] * shape[1]))\n",
    "        self.state = None\n",
    "\n",
    "    def random(self, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize the state of the network with random values of +1 and -1.\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.state = np.random.choice([-1, 1], size=self.shape)\n",
    "\n",
    "    def train(self, patterns):\n",
    "        \"\"\"\n",
    "        Train the network using the Hebbian learning rule.\n",
    "        \n",
    "        Parameters:\n",
    "          patterns: A list of binary patterns (numpy arrays of -1 and 1) to be stored.\n",
    "        \"\"\"\n",
    "        for p in patterns:\n",
    "            assert p.shape == self.shape\n",
    "            p_flat = p.flatten()\n",
    "            self.W += np.outer(p_flat, p_flat)\n",
    "        np.fill_diagonal(self.W, 0)  # Ensure no neuron connects to itself\n",
    "        self.W /= len(patterns)      # Normalize by the number of patterns\n",
    "\n",
    "    @staticmethod\n",
    "    def step(state, i, j, W):\n",
    "        \"\"\"\n",
    "        Update a single neuron using the network's weight matrix.\n",
    "        \"\"\"\n",
    "        index = i * state.shape[1] + j\n",
    "        state[i, j] = np.sign(np.dot(W[index], state.flatten()))\n",
    "\n",
    "    def run(self, N):\n",
    "        \"\"\"\n",
    "        Evolve the network for N iterations.\n",
    "        \"\"\"\n",
    "        for _ in range(N):\n",
    "            i = np.random.randint(0, self.shape[0])\n",
    "            j = np.random.randint(0, self.shape[1])\n",
    "            self.step(self.state, i, j, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an image loader that read and convert an image to binary (-1, 1) using `matplotlib`\n",
    "\n",
    "def load_image(filename):\n",
    "    im = img.imread(filename)\n",
    "    if im.ndim == 3:\n",
    "        im = np.mean(im, axis=-1)   # Convert to grayscale if needed\n",
    "    im = np.where(im < 128, -1, 1)  # Convert grayscale to binary (-1, 1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and display them\n",
    "\n",
    "im1 = load_image(\"images/AI.jpg\")\n",
    "im2 = load_image(\"images/cloud.jpg\")\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(im1, cmap='gray')\n",
    "ax0.set_title('Pattern \"AI\"')\n",
    "ax1.imshow(im2, cmap='gray')\n",
    "ax1.set_title('Pattern \"cloud\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Hopfield Network\n",
    "\n",
    "h = HopfieldNetwork()\n",
    "h.train([im1, im2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Network\n",
    "\n",
    "h.random()      # Initialize a random state \n",
    "h.run(64*64*8)  # ... and evolve it to retrieve a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the retrieved pattern\n",
    "\n",
    "plt.imshow(h.state, cmap='gray')\n",
    "plt.title(\"Retrieved Pattern\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDS-ON: instead of just visualizing the final output, implement a loop to create a movie\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDS-ON: instead of starting randomly, introduce structured noise to observe how the network behaves.\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDS-ON: load additional images and test the network's recall capacity\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## 6. Discussion (5 min)\n",
    "- **Real-World Applications:**\n",
    "  - How neural networks are used in AI, data analysis, and more.\n",
    "- **Ethical Considerations:**\n",
    "  - Discuss fairness, biases, and the impact of AI on society.\n",
    "- **Closing Questions:**\n",
    "  - How do physics and AI work together in models like the Ising model and Hopfield Networks?\n",
    "  - Encourage further exploration with tools like Jupyter Notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
