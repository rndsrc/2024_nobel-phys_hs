{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rndsrc/2024_nobel-phys_hs/blob/main/Hopfield.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Exploring the 2024 Nobel Prize in Physics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 0. Setup (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Access the Notebook\n",
    "\n",
    "To start working with this notebook, open it using one of the following methods:\n",
    "\n",
    "- [**GitHub Codespaces**](https://github.com/features/codespaces): If you are using a GitHub repository, you can launch a Codespace, which provides an online VS Code environment with Jupyter support.\n",
    "- [**Google Colab**](https://colab.research.google.com/): If you prefer a cloud-based Python environment, open this notebook in Google Colab.\n",
    "- **Local Jupyter Lab:** If you have Jupyter installed on your machine, run the following command in your terminal: `jupyter lab`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Quick Tour of Jupyter Notebook\n",
    "\n",
    "Jupyter Notebook consists of **cells** that can contain either **Markdown** (formatted text) or **Python code**.\n",
    "\n",
    "- **Markdown Cells:** Used for documentation and instructions.\n",
    "  Double-click a cell to edit it, and press `Shift + Enter` to render it.\n",
    "- **Code Cells:** Used to write and execute Python code.\n",
    "  Click inside a cell and press `Shift + Enter` to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Example: Run Your First Python Code\n",
    "\n",
    "Try running the following code cell to check if Python is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a testing welcome message\n",
    "\n",
    "def greet():\n",
    "    return \"Welcome to the Hopfield Network Notebook!\"\n",
    "\n",
    "print(greet())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Installing Dependencies (if needed)\n",
    "\n",
    "In a Jupyter Notebook, an `!` (exclamation mark) is used to execute shell (command-line) commands directly from a code cell.\n",
    "This allows users to run commands as they would in a terminal, without leaving the notebook.\n",
    "If running this notebook locally, ensure you have the required libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Shell out\" to the operating system to install the necessary packages\n",
    "\n",
    "! pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "\n",
    "To make it more fun, we will create animation and work with images along the way.\n",
    "These are plotting details that we don't need to spend time on.\n",
    "Just run the following cell to make sure the `animate()` and `load()` functions are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define `animate(state, Nsub=100, N=250)` to create animation and `load(filename)` to load image files\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image  as img\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import numpy as np\n",
    "from   numpy.random import randint\n",
    "\n",
    "def animate(state, update, nsub=100, n=250, cmap='viridis'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "    im = ax.imshow(state, cmap=cmap)\n",
    "    def func(i):\n",
    "        update(state, nsub)\n",
    "        im.set_array(state)\n",
    "        return [im]\n",
    "    an = FuncAnimation(fig, func, frames=n, interval=40, blit=True)\n",
    "    plt.close()\n",
    "    return an\n",
    "\n",
    "def load(filename):\n",
    "    im = img.imread(filename)\n",
    "    if im.ndim == 3:\n",
    "        im = np.mean(im, axis=-1)   # Convert to grayscale if needed\n",
    "    im = np.where(im < 128, -1, 1)  # Convert grayscale to binary (-1, 1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "This concludes the setup!\n",
    "Now, let's dive into Hopfield networks and their connection to the Ising model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 1. Introduction (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### What is the 2024 Nobel Prize in Physics About?\n",
    "\n",
    "In 2024, the **Nobel Prize in Physics** was awarded to **John J. Hopfield** and **Geoffrey E. Hinton** for their pioneering work on neural networks.\n",
    "Their contributions have played a significant role in the development of modern artificial intelligence and computational models inspired by biological learning mechanisms.\n",
    "\n",
    "- **John J. Hopfield** introduced the Hopfield network, a type of recurrent neural network that models associative memory and collective computation in neural systems.\n",
    "- **Geoffrey E. Hinton** made significant advancements in deep learning, particularly in training deep neural networks through the backpropagation algorithm.\n",
    "\n",
    "Their research has had profound implications in artificial intelligence, neuroscience, and computational physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Why Do Neural Networks Matter?\n",
    "\n",
    "Neural networks are now an essential part of many everyday technologies:\n",
    "\n",
    "- **Facial Recognition:** Used to unlock smartphones and enhance security.\n",
    "- **Chatbots:** Power customer service agents that interact with users.\n",
    "- **Voice Assistants:** Siri, Alexa, and Google Assistant rely on neural networks for speech recognition.\n",
    "- **Self-Driving Cars:** Autonomous vehicles process sensor data using deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Importance of This Discovery\n",
    "\n",
    "Neural networks have revolutionized multiple domains, including:\n",
    "- **Language Translation:** Real-time translation services are powered by deep learning models.\n",
    "- **Medical Diagnosis:** AI-assisted analysis of medical images improves diagnostic accuracy.\n",
    "- **Scientific Research:** AI-driven simulations enhance modeling in physics, chemistry, and biology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 2. The Ising Model (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### What Is the Ising Model?\n",
    "\n",
    "To understand how neural networks operate, we first introduce the **Ising model**.\n",
    "\n",
    "The **Ising model** is a mathematical model in statistical mechanics, introduced by Wilhelm Lenz in 1920 and solved for the one-dimensional case by his student Ernst Ising in 1925.\n",
    "The model was originally used to explain ferromagnetism, where magnetic materials exhibit spontaneous magnetization due to interactions between neighboring atomic spins.\n",
    "\n",
    "- Wilhelm Lenz conceived the model as a simplified representation of magnetic interactions in a lattice, where spins can either point \"up\" (+1) or \"down\" (-1).\n",
    "- Ernst Ising solved the one-dimensional version of the model in his doctoral thesis, showing that it did not exhibit phase transitionsâ€”a result that was surprising at the time.\n",
    "- Lars Onsager solved the two-dimensional version of the model in 1944, demonstrating that it undergoes a phase transition at a critical temperature, where spontaneous magnetization occurs.\n",
    "\n",
    "Since then, the Ising model has become one of the most widely studied models in statistical physics and beyond.\n",
    "Its applications extend not only to physics (such as in magnetism and lattice gases) but also to fields like biology (neural networks), computer science (optimization problems), and even sociology (modeling opinion dynamics).\n",
    "\n",
    "The **Metropolis algorithm** (1953) was developed for Monte Carlo simulations of systems like the Ising model, enabling the study of large, complex systems by simulating their thermal fluctuations and statistical properties.\n",
    "This method revolutionized computational physics and remains a powerful tool in many areas of research today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Basic Idea\n",
    "\n",
    "- Consider a **grid (lattice)** where each point represents a **spin**.\n",
    "- Each spin can take one of two states: **up (+1) or down (-1)**.\n",
    "- Spins interact with their neighbors, aiming to align in a way that minimizes system energy.\n",
    "- The system's **energy parameter** determines the likelihood of spins flipping, making temperature a crucial factor in system behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Let's start programming as we introduce the different concepts.\n",
    "Here, we create a python class to keep track of the state and temperature of an Ising Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass a numpy array to store the state of an Ising Model\n",
    "\n",
    "class Ising(np.ndarray):\n",
    "\n",
    "    def __new__(cls, shape=(64,64), kT=1, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        obj = np.random.choice([-1,1], size=shape).view(cls)\n",
    "        obj.kT = kT\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        if obj is None: return\n",
    "        self.kT = getattr(obj, 'kT', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "With the class `Ising`, we can now instanize a Ising model by creating a 2D grid of spin state:\n",
    "```python\n",
    "ising = Ising(seed=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: instanize a Ising model by creating a 2D grid of spin state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "We can visualize the spin state by plotting `ising` as an image:\n",
    "```python\n",
    "plt.imshow(ising)\n",
    "```\n",
    "You may try out different [colormaps](https://matplotlib.org/stable/users/explain/colors/colormaps.html) by specifying the `cmap` keyword, e.g.,\n",
    "```python\n",
    "plt.imshow(ising, cmap='coolwarm')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: visualize the spin state by plotting the state as an image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Interaction and Energy Minimization\n",
    "\n",
    "- The system's total energy is determined by how well-aligned the spins are with their neighbors.\n",
    "- At **high temperatures**, spins flip frequently due to thermal fluctuations, leading to disorder.\n",
    "- At **low temperatures**, spins align into ordered configurations, exhibiting phase transitions similar to those in magnetic materials.\n",
    "- The **Hamiltonian** (energy function) for the Ising model is:\n",
    "  $$\n",
    "  H = - \\sum_{i,j} J_{ij} s_i s_j\n",
    "  $$\n",
    "  where:\n",
    "  - $s_i$ represents the spin at site $i$.\n",
    "  - $J_{ij}$ is the coupling strength between neighboring spins.\n",
    "- The system evolves dynamically to minimize $H$, leading to patterns of stable configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Energy Change Due to Spin Flip\n",
    "\n",
    "When a single spin $s_i$ flips, the change in energy is calculated by comparing the energy before and after the flip.\n",
    "The energy difference $\\Delta E$ due to flipping the spin at site $i$ is:\n",
    "$$\n",
    "\\Delta E = 2 s_i \\sum_{j} J_{ij} s_j,\n",
    "$$\n",
    "where the sum is over the nearest neighbors $j$ of site $i$.\n",
    "The factor of 2 arises because flipping the spin at site $i$ changes its contribution to the energy from $-s_i s_j$ to $+s_i s_j$.\n",
    "\n",
    "Choose $J_{ij}$ so that only neighborhood cells have interaction 1, we can implement the following function:\n",
    "```python\n",
    "def energy_change(ising, i, j):\n",
    "    I, J = ising.shape  # Get lattice dimensions\n",
    "    spin = ising[i, j]  # Current spin value\n",
    "    \n",
    "    # Neighboring spins (periodic boundary conditions)\n",
    "    neighbors = (  ising[(i+1)%I, j] \n",
    "                 + ising[(i-1)%I, j]\n",
    "                 + ising[i, (j+1)%J]\n",
    "                 + ising[i, (j-1)%J])\n",
    "\n",
    "    # Energy difference due to spin flip\n",
    "    return 2 * spin * neighbors\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please fill out the blanks ___ of the following function\n",
    "\n",
    "def energy_change(ising, i, j):\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We may now obtain the energy change for flipping a spin at different cells:\n",
    "```python\n",
    "energy_change(ising, 1, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: choose different i and j and compute the energy change by calling `energy_change(state, i, j)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Metropolis Algorithm\n",
    "\n",
    "To simulate the evolution of the system at a given temperature, we use the Metropolis algorithm.\n",
    "This algorithm probabilistically accepts or rejects a spin flip based on the energy change $\\Delta E$ and the temperature $T$.\n",
    "The probability of accepting a spin flip is given by the Boltzmann factor:\n",
    "$$\n",
    "P(\\text{flip}) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } \\Delta E < 0, \\\\\n",
    "\\exp\\left(-\\frac{\\Delta E}{k T}\\right) & \\text{if } \\Delta E \\geq 0,\n",
    "\\end{cases}\n",
    "$$\n",
    "where:\n",
    "- $\\Delta E$ is the energy change caused by the flip.\n",
    "- $k$ is the Boltzmann constant.\n",
    " $T$ is the temperature.\n",
    "\n",
    "This allows the system to \"explore\" higher energy states at higher temperatures (thermal fluctuations), while favoring low-energy configurations as the system cools down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "We can implement a function `flip(ising, i, j)` to determent if we need to flip the spin `ising` at grid `i`, `j`:\n",
    "```python\n",
    "def flip(ising, i, j):\n",
    "    dE = energy_change(ising, i, j)  # Compute energy change\n",
    "    \n",
    "    if dE < 0:  # Check the sign of energy change\n",
    "        return True  # Always accept flip if energy decreases\n",
    "    else:\n",
    "        return np.random.rand() < np.exp(-dE / ising.kT)  # Accept flip with Boltzmann probability\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please fill out the blanks ___ of the following function\n",
    "\n",
    "def flip(ising, i, j):\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Note the `np.random.rand()` function in `flip()`.\n",
    "Choose a cell with positive energy change and run flip multiple times.\n",
    "What do you see?\n",
    "```python\n",
    "for _ in range(100):\n",
    "    print(flip(ising, 1, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: try repeat flip() multiple times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "What happen if you change the temperature?\n",
    "```python\n",
    "ising1 = Ising(kT=10, seed=42)\n",
    "for _ in range(100):\n",
    "    print(flip(ising1, 1, 1))\n",
    "\n",
    "ising2 = Ising(kT=0.1, seed=42)\n",
    "for _ in range(100):\n",
    "    print(flip(ising2, 1, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: try change `kT` and then repeat flip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "With the above helper functions, we are ready to implement the Ising Model using the metropolis algorithm:\n",
    "```python\n",
    "def run(ising, N):\n",
    "    for _ in range(N):  # Repeat the simulation N times\n",
    "        i = randint(0, ising.shape[0])  # Random row index\n",
    "        j = randint(0, ising.shape[1])  # Random column index\n",
    "        if flip(ising, i, j):  # Check if we need to flip the spin\n",
    "            ising[i, j] *= -1  # Actually flip the spin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please fill out the blanks ___ of the following function\n",
    "\n",
    "def run(ising, N):\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "That's it!\n",
    "We can how compare the spin state before\n",
    "```python\n",
    "plt.imshow(ising)\n",
    "```\n",
    "and after the simulation:\n",
    "```python\n",
    "run(ising, 100_000)\n",
    "plt.imshow(ising)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: visualize the initial spin state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: run the simuluation for, e.g., 100,000 steps, and then visualize the final spin state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We've created two additional states above with different temperature.\n",
    "How do the spin states look like after simulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: run the simuluation for spin states with different temperature; visualize the final spin state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Animate the Ising Model\n",
    "\n",
    "Just for fun, we can now combine the implemented Ising model with the `animate(state, update, nsub, n)` helper function that we defined at the very beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "The `run()` function that we implemented actually has the same call signature as the `update()` function.\n",
    "Hence, we can use it to create the animation:\n",
    "```python\n",
    "ising = Ising()\n",
    "an = animate(ising, run)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: use the animate(state, update, nsub, n) to create an animation object `an`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Finally, we can show the animation as a movie:\n",
    "```python\n",
    "HTML(an.to_html5_video())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: show the animation object as a video\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Why It Matters\n",
    "\n",
    "#### Real-World Example: Magnets and Decision-Making\n",
    "- In **magnetism**, atomic spins align to form magnetic domains, illustrating how interactions shape large-scale behavior.\n",
    "- In **social dynamics**, human decision-making can resemble an Ising model, where individuals adjust their opinions based on peer influence.\n",
    "\n",
    "#### Optimization\n",
    "- Many complex optimization problems, including **image recognition and combinatorial search problems**, can be formulated using the Ising model framework.\n",
    "- The process of **energy minimization** in the Ising model is analogous to **error minimization** in machine learning.\n",
    "- Neural networks, particularly **Hopfield networks** that we will present later, use a similar principle to find stable memory states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 3. Hopfield Networks (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Memory Machines\n",
    "\n",
    "The **Hopfield network**, introduced by **John Hopfield in 1982**, is a recurrent neural network that stores and recalls patterns through energy minimization.\n",
    "\n",
    "- **Pattern Storage and Recall:** The network can store multiple patterns as stable configurations.\n",
    "- **Robustness to Noise:** If an input is noisy or incomplete, the network still retrieves the correct stored pattern.\n",
    "- **Content-Addressable Memory:** Unlike conventional memory, which retrieves data using addresses, Hopfield networks retrieve patterns based on similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Energy Landscape\n",
    "\n",
    "The Hopfield network shares deep similarities with the Ising model:\n",
    "- **Neurons replace spins**, taking binary values $+1$ or $-1$.\n",
    "- **Connections between neurons** correspond to interactions between spins.\n",
    "- **The system evolves toward stable, low-energy states**, just like in the Ising model.\n",
    "- **Both exhibit emergent global order** despite being governed by local interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "The energy function of the Hopfield network is given by:\n",
    "$$\n",
    "E = - \\sum_{i,j} W_{ij} \\sigma_i \\sigma_j,\n",
    "$$\n",
    "where $W_{ij}$ represents synaptic weights and $\\sigma_i$ is the neuron state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "When a neuron updates, its **energy change** follows:\n",
    "$$\n",
    "\\Delta E = 2 \\sigma_i \\sum_j W_{ij} \\sigma_j.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Why It Matters\n",
    "\n",
    "The Hopfield network played a **foundational role in artificial intelligence** by introducing energy-based models:\n",
    "- Inspired later developments such as **Boltzmann machines** and **Deep Learning architectures**.\n",
    "- Showed how memory and pattern recognition could emerge from simple neuron interactions.\n",
    "- Provided insights into **biological neural networks**, helping us understand how the brain processes and retrieves information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Because of the similar between a Hopfield network and Ising model, similar, we subclass a numpy array to store the state of a Hopfield network.\n",
    "Instead of keeping track of the model's temperature `kT`, we create an empty array `W` to store the synaptic weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass a numpy array to store the state of a Hopfield network\n",
    "\n",
    "class Hopfield(np.ndarray):\n",
    "\n",
    "    def __new__(cls, shape=(64,64), seed=None):\n",
    "        N = shape[0] * shape[1]\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        obj   = np.random.choice([-1,1], size=shape).view(cls)\n",
    "        obj.W = np.zeros((N, N))\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        if obj is None: return\n",
    "        self.W = getattr(obj, 'W', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "By default, an instance of the Hopfield class is random.\n",
    "Let's instanize one and visualize it:\n",
    "```python\n",
    "hopfield = Hopfield()\n",
    "plt.imshow(hopfield, cmap='gray')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: instanize a Hopfield network and visualize its initial random state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### Hebbian Learning Rule\n",
    "\n",
    "The weights in a Hopfield network are learned using the Hebbian learning rule, which strengthens the connections between neurons that are activated together.\n",
    "It is given by:\n",
    "$$\n",
    "W_{ij} = \\frac{1}{P} \\sum_p \\sigma_i^{(p)} \\sigma_j^{(p)}.\n",
    "$$\n",
    "Where:\n",
    "* $N$ is the number of neurons.\n",
    "* $P$ is the number of patterns.\n",
    "* $\\sigma_i^{(p)}$ is the state of neuron $i$ in a pattern $p$.\n",
    "\n",
    "This makes Hopfield networks **powerful for associative memory**, allowing pattern retrieval even with noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Using `numpy`'s function, it is straightforward to implement Hebbian's learning rule:\n",
    "```python\n",
    "def learn(hopfield, patterns):\n",
    "    for pattern in patterns:  # Hopfield network can learn multiple patterns\n",
    "        assert pattern.shape == hopfield.shape  # Ensure pattern shape matches the state shape\n",
    "        p = pattern.flatten()\n",
    "        hopfield.W += np.outer(p, p)  # The Hebbian Learning Rule is mathematically an outer product\n",
    "        \n",
    "    np.fill_diagonal(hopfield.W, 0)  # Ensure no neuron connects to itself\n",
    "    hopfield.W /= len(patterns)      # Normalize by the number of patterns\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please fill out the blanks ___ of the following function\n",
    "\n",
    "def learn(hopfield, patterns):\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "To test it out, let's download some sample images and read them with the `load()` function that we defined at the beginning.\n",
    "Because downloading images does not affect our understanding of Hopfield network, let's just run the following code cells directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from GitHub in case this notebook is opened in Google colab\n",
    "\n",
    "url  = \"https://raw.githubusercontent.com/rndsrc/2024_nobel-phys_hs/refs/heads/main/images/\"\n",
    "url1 = url + \"AI.jpg\"\n",
    "url2 = url + \"cloud.jpg\"\n",
    "url3 = url + \"computer.jpg\"\n",
    "\n",
    "! if [ ! -d images ]; then mkdir images && cd images && wget {url1} && wget {url2} && wget {url3}; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and display them\n",
    "\n",
    "im1 = load(\"images/AI.jpg\")\n",
    "im2 = load(\"images/cloud.jpg\")\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(im1, cmap='gray')\n",
    "ax0.set_title('Pattern \"AI\"')\n",
    "ax1.imshow(im2, cmap='gray')\n",
    "ax1.set_title('Pattern \"cloud\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "With these sample images, let's make our Hopfield network learn from these patterns.\n",
    "Note that the state of the Hopfield network has not change.\n",
    "It is still random.\n",
    "```python\n",
    "learn(hopfield, [im1, im2])\n",
    "plt.imshow(hopfield, cmap='gray')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: check what happen to the Hopfield state after learning the patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Once the patterns are learn, we can recall each pixel value by:\n",
    "\\begin{align}\n",
    "  \\sigma_i^{(p)} = \\text{sgn}\\left(\\sum_j W_{ij} \\sigma_j^{(p)}\\right)\n",
    "\\end{align}\n",
    "which can be implemented as:\n",
    "```python\n",
    "def recall(hopfield, N):\n",
    "    for _ in range(N):\n",
    "        i = randint(0, hopfield.shape[0])  # Random row index\n",
    "        j = randint(0, hopfield.shape[1])  # Random column index\n",
    "        \n",
    "        # Update a single pixel in the pattern\n",
    "        index = i * hopfield.shape[1] + j\n",
    "        hopfield[i, j] = np.sign(np.dot(hopfield.W[index], hopfield.flatten()))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please fill out the blanks ___ of the following function\n",
    "\n",
    "def recall(hopfield, N):\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "That's it!\n",
    "We've implemented all the functions of the Hopfield network!\n",
    "We can \"recall\" its memory and visulize the result by:\n",
    "```python\n",
    "recall(hopfield, 100_000)\n",
    "plt.imshow(hopfield, cmap='gray')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: recall a pattern and visualize the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### Animate the Hopfield Network\n",
    "\n",
    "Just for fun again, we can now combine the implemented Hopfield network with the `animate(state, update, nsub, n)` helper function that we defined at the very beginning.\n",
    "\n",
    "The `recall()` function that we implemented actually has the same call signature as the `update()` function.\n",
    "Hence, we can use it to create the animation:\n",
    "```python\n",
    "hopfield = Hopfield()\n",
    "learn(hopfield, [im1, im2])\n",
    "an = animate(hopfield, recall, cmap='gray')\n",
    "HTML(an.to_html5_video())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: animate memory recall of a Hopfield network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "## 4. Discussion (5 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Closing Questions\n",
    "\n",
    "This notebook has demonstrated how **concepts from physics and AI intersect** through models like the Ising Model and Hopfield Networks.\n",
    "Here are some questions to encourage further exploration:\n",
    "\n",
    "- How do energy minimization principles in physics apply to AI and machine learning?\n",
    "- Can you think of other real-world phenomena that could be modeled using energy-based systems?\n",
    "- How might AI benefit from further insights from statistical mechanics and physics?\n",
    "- What improvements could be made to the Hopfield Network to make it more efficient?\n",
    "\n",
    "For further study, students can explore more advanced models such as Boltzmann Machines, Restricted Boltzmann Networks, and Deep Learning frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "- Experiment with different **patterns and noise levels** in the Hopfield Network.\n",
    "- Modify the **weight update rules** to observe how the network behaves.\n",
    "- Implement more **complex datasets** and evaluate performance.\n",
    "- Use **Jupyter Notebooks** as a tool to explore AI and physics simulations further.\n",
    "\n",
    "This discussion wraps up our **Exploring the 2024 Nobel Prize in Physics**.\n",
    "We hope this notebook inspires curiosity and further learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
